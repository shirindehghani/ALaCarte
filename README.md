# ALaCarte word embedding

This is an unofficial implementation of the AlaCarte word embedding, which is a lightweight method. It is as efficient as contextualized embeddings like BERT.

![Alt text](image URL)

To run this code, you should download [Glove Vectors](https://nlp.stanford.edu/projects/glove/) and add them to the models directory.

Note that this preprocessing is created for English language! for other languages you should change preprocessing and also ```stopwords```.
